from nltk.tokenize import word_tokenize
from Levenshtein import distance
import numpy as np

def get_stt_words(wordlevel_info):
    """
    Extract the STT words from word-level timing information.

    Args:
    wordlevel_info (list): List of dictionaries containing word-level timing information.

    Returns:
    list: List of words generated by STT.
    """
    return [info['word'] for info in wordlevel_info]


def align_texts_dynamic(original_words, stt_words):
    """
    Align the original script with the STT output using a dynamic programming approach.

    Args:
    original_words (list): List of words from the original video script.
    stt_words (list): List of words generated by STT.

    Returns:
    list: Alignment result as a list of tuples (original_word, stt_word), where None indicates an insertion or deletion.
    
    This function performs the following steps:
    1. Initializes a cost matrix with high values to represent the cost of aligning the sequences.
    2. Fills the cost matrix based on insertion, deletion, and substitution costs.
    3. Uses backtracking to find the optimal alignment path by tracing the minimum cost path in the matrix.
    4. Returns the alignment result, which indicates how each word in the STT output aligns with the original script, handling insertions and deletions.
    """

    # Step 1. Initialize the cost matrix with high values
    dp = np.full((len(stt_words) + 1, len(original_words) + 1), len(original_words) + len(stt_words))
    dp[0, :] = range(len(original_words) + 1)
    dp[:, 0] = range(len(stt_words) + 1)

    # Step 2. Fills the cost matrix based on insertion, deletion, and substitution costs.
    for i, word_stt in enumerate(stt_words, start=1):
        for j, word_orig in enumerate(original_words, start=1):
            cost = distance(word_stt, word_orig)
            dp[i, j] = min(dp[i-1, j] + 1, dp[i, j-1] + 1, dp[i-1, j-1] + cost)

    # Step 3. Backtracking to find the alignment
    i, j = len(stt_words), len(original_words)
    alignment = []

    while i > 0 or j > 0:
        current_cost = dp[i, j]
        if i > 0 and dp[i-1, j] + 1 == current_cost:
            alignment.append((stt_words[i-1], None))
            i -= 1
        elif j > 0 and dp[i, j-1] + 1 == current_cost:
            alignment.append((None, original_words[j-1]))
            j -= 1
        else:
            alignment.append((stt_words[i-1], original_words[j-1]))
            i -= 1
            j -= 1

    alignment.reverse()

    return alignment


def calculate_proportional_times(temp_start_time, end_time, temp_words, orig_word):
    """
    In case the STT system doesn't detect a word or the original text includes words that aren't in the audio speech (eg. "Je veux pas" -> "Je ne veux pas"),
    as we still wan't them to be highlighted, we'll split the correct_word time (when both words are paired in the list) between previous missing words and itself.
    Calculate the proportional end time for temp_words and start time for orig_word based on their character lengths.

    Args:
    temp_start_time (float): Start time for the missing words.
    end_time (float): Start time of the current word.
    temp_words (str): Accumulated missing words.
    orig_word (str): Current word.

    Returns:
    tuple: (temp_word_end_time, orig_word_start_time) - Proportional end time for temp_words and start time for orig_word.
    """
    total_duration = end_time - temp_start_time
    temp_word_len = len(temp_words)
    orig_word_len = len(orig_word)
    total_len = temp_word_len + orig_word_len

    temp_word_end_time = round(temp_start_time + (total_duration * temp_word_len / total_len), 2)
    orig_word_start_time = temp_word_end_time

    return temp_word_end_time, orig_word_start_time


def start_time_missing_words(start_index, wordlevel_info):
    """
    Determine the start time for missing words based on the current index and missing_word_count.

    Args:
    start_index (int): Index of the current word's start.
    wordlevel_info (list): List of dictionaries containing word-level timing information.

    Returns:
    float: The start time for the missing words.
    """
    if (start_index) < len(wordlevel_info):
        return wordlevel_info[start_index]['start']
    else:
        return wordlevel_info[-1]['start']


def append_missing_words(updated_info, temp_words, temp_start_time, end_time):
    """
    Append missing words to the updated_info list with calculated start and end times.

    Args:
    updated_info (list): List to store the updated word-level timing information.
    temp_words (str): Accumulated missing words.
    temp_start_time (float): Start time for the missing words.
    end_time (float): End time for the missing words.

    Returns:
    None
    """
    updated_info.append({
        'word': temp_words, 
        'start': temp_start_time, 
        'end': end_time
    })


def append_current_word(updated_info, orig_word, start_time, end_time):
    """
    Append the current word to the updated_info list with its start and end times.

    Args:
    updated_info (list): List to store the updated word-level timing information.
    orig_word (str): Current word.
    start_time (float): Start time for the current word.
    end_time (float): End time for the current word.

    Returns:
    None
    """
    updated_info.append({
        'word': orig_word, 
        'start': start_time, 
        'end': end_time
    })


def process_missing_word(i, orig_word, temp_words, temp_start_time, missing_stt_flag, missing_word_count, wordlevel_info):
    """
    Process a missing word, updating temp_words, temp_start_time, and flags.

    Args:
    i (int): Current index in the alignment.
    orig_word (str): Original word from the alignment.
    temp_words (str): Accumulated missing words.
    temp_start_time (float): Start time for the missing words.
    missing_stt_flag (bool): Flag indicating if there are missing STT words.
    missing_word_count (int): Number of missing words so far.
    wordlevel_info (list): List of dictionaries containing word-level timing information.

    Returns:
    tuple: Updated (temp_words, temp_start_time, missing_stt_flag, missing_word_count).
    """
    if not missing_stt_flag:
        temp_start_time = start_time_missing_words(i - missing_word_count, wordlevel_info)
    
    if orig_word not in [".", ",", "'"]:
        temp_words += " "
    temp_words += orig_word
    missing_stt_flag = True
    missing_word_count += 1
    
    return temp_words, temp_start_time, missing_stt_flag, missing_word_count


def process_several_words(i, orig_word, temp_words, temp_start_time, updated_info, missing_word_count, wordlevel_info):
    """
    Process both present words, calculate proportional times, and update relevant variables.

    Args:
    i (int): Current index in the alignment.
    orig_word (str): Original word from the alignment.
    temp_words (str): Accumulated missing words.
    temp_start_time (float): Start time for the missing words.
    updated_info (list): List to store the updated word-level timing information.
    missing_word_count (int): Number of missing words so far.
    wordlevel_info (list): List of dictionaries containing word-level timing information.

    Returns:
    tuple: Updated (temp_words, missing_stt_flag).
    """
    end_time = wordlevel_info[i - missing_word_count]['start']
    temp_word_end_time, orig_word_start_time = calculate_proportional_times(temp_start_time, end_time, temp_words, orig_word)
    
    append_missing_words(updated_info, temp_words, temp_start_time, temp_word_end_time)
    append_current_word(updated_info, orig_word, orig_word_start_time, wordlevel_info[i - missing_word_count]['end'])
    
    temp_words = ""
    return temp_words, False


def update_wordlevel_info_based_on_alignment(alignment, wordlevel_info):
    """
    Update word-level timing information based on alignment between STT output and original text.

    Args:
    alignment (list): List of tuples representing aligned words from STT output and original text.
    wordlevel_info (list): List of dictionaries containing word-level timing information.

    Returns:
    list: Updated list of dictionaries with word-level timing information.
    """
    updated_info = []
    temp_start_time = 0
    temp_words = ""
    missing_stt_flag = False
    missing_word_count = 0

    for i, (stt_word, orig_word) in enumerate(alignment):
        # When orig_word has been inserted
        if stt_word is None:
            temp_words, temp_start_time, missing_stt_flag, missing_word_count = process_missing_word(
                i, orig_word, temp_words, temp_start_time, missing_stt_flag, missing_word_count, wordlevel_info)
        # When both words are present (words look like each others)
        elif stt_word is not None and orig_word is not None:
            # If missing words have already been registered, process them with the original word
            if missing_stt_flag:
                temp_words, missing_stt_flag = process_several_words(
                    i, orig_word, temp_words, temp_start_time, updated_info, missing_word_count, wordlevel_info)
            else:
                append_current_word(updated_info, orig_word, wordlevel_info[i - missing_word_count]['start'], wordlevel_info[i - missing_word_count]['end'])

    # If the end of the list contains missing words, the alignment process won't be triggered (it needs both words to be present), thus we process them
    if missing_stt_flag and temp_words:
        temp_word_end_time = wordlevel_info[-1]['end']
        append_missing_words(updated_info, temp_words, temp_start_time, temp_word_end_time)

    return updated_info


def correct_generated_text_with_script(video_script, wordlevel_info):
    """
    Correct the generated STT word-level information using the provided video script.

    Args:
    video_script (str): The script of the video as a string.
    wordlevel_info (list): List of dictionaries containing word-level timing information generated by STT.

    Returns:
    list: Updated list of dictionaries with corrected word-level timing information.
    """
    if video_script == "":
        return wordlevel_info
    
    script = word_tokenize(video_script)
    stt_words = get_stt_words(wordlevel_info)
    alignment_result = align_texts_dynamic(script, stt_words)
    updated_wordlevel_info = update_wordlevel_info_based_on_alignment(alignment_result, wordlevel_info)

    return updated_wordlevel_info